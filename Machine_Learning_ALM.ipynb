{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPS3GRtrWfRCZomCBKHN0nd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gopikanta/Machine-Learning---LAB/blob/main/Machine_Learning_ALM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbqtBq4OqL5",
        "outputId": "078ee572-bc25-484e-fb4f-f1f3a289f43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#Program no : 1\n",
        "#Build a small Convolutional Neural Network (CNN) model using any of deep libraries for:\n",
        "\n",
        "# a) Image Recognition/ Classification\n",
        "\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output and add dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes for classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZuH1eFVRtDz",
        "outputId": "e878772f-1f7a-4641-c586-2a31ae002c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               11075712  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11170250 (42.61 MB)\n",
            "Trainable params: 11170250 (42.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a small Convolutional Neural Network (CNN) model using any of deep libraries for:\n",
        "# b) Digit Identification\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J0-xfx7Sh3e",
        "outputId": "0c68465b-aac5-4f7f-8761-ea1fb7a0f070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93322 (364.54 KB)\n",
            "Trainable params: 93322 (364.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 52s 54ms/step - loss: 0.1754 - accuracy: 0.9469 - val_loss: 0.0572 - val_accuracy: 0.9824\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 0.0512 - accuracy: 0.9839 - val_loss: 0.0329 - val_accuracy: 0.9905\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.0427 - val_accuracy: 0.9871\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 48s 52ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0419 - val_accuracy: 0.9876\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.0222 - val_accuracy: 0.9923\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ff9ec4f18d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Program no: 2\n",
        "# How to use Pre-trained CNN models for feature extraction.\n",
        "\n",
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2afPM2uUnmI",
        "outputId": "9dd77072-c565-468c-c4d3-0e3d7ca4006c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load a pre-trained VGG16 model (excluding the top classification layer)\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Function to load and preprocess an image\n",
        "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Function to perform feature extraction using the pre-trained model\n",
        "def extract_features(img_array):\n",
        "    features = base_model.predict(img_array)\n",
        "    return features\n",
        "\n",
        "# Path to an example image\n",
        "image_path = '/content/alm.jpg'\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_array = load_and_preprocess_image(image_path)\n",
        "\n",
        "# Extract features using the pre-trained VGG16 model\n",
        "extracted_features = extract_features(img_array)\n",
        "\n",
        "# Print the shape of the extracted features\n",
        "print(\"Shape of extracted features:\", extracted_features.shape)\n",
        "\n",
        "# Optionally, you can flatten the features if you want a 1D representation\n",
        "flattened_features = extracted_features.flatten()\n",
        "print(\"Shape of flattened features:\", flattened_features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFnzA6LkWKmP",
        "outputId": "7a0b5174-c5aa-4954-edc4-dd395fe282ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Shape of extracted features: (1, 7, 7, 512)\n",
            "Shape of flattened features: (25088,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Program no: 3\n",
        "# Implementation of Pre-trained CNN models using transfer learning for classification/object detections.\n",
        "# a) AlexNet\n",
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWuewr_PXH-G",
        "outputId": "c9e2d7d0-b312-4c4c-ba95-b9e086842bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def AlexNet(input_shape, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "        Conv2D(256, kernel_size=(5,5), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "        Conv2D(384, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        Conv2D(384, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the number of classes in your dataset\n",
        "num_classes = 10  # Change this according to your dataset\n",
        "\n",
        "# Create AlexNet model\n",
        "input_shape = (224, 224, 3)\n",
        "model = AlexNet(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Prepare data\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'train_dir',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Print summary of the model\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Print training history\n",
        "print(history.history)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('alexnet_transfer_learning_model.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('alexnet_transfer_learning_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "XWwO7mTeE8Tf",
        "outputId": "abeb3b44-cab8-4293-86ed-b448bc5b5eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train_dir'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-961d0f3c8125>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtrain_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;34m'train_dir'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \"\"\"\n\u001b[0;32m-> 1649\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1650\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_dir'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementation of Pre-trained CNN models using transfer learning for classification/object detections.\n",
        "#b) VGG-16\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Load pre-trained VGG16 model without classification layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('vgg16_transfer_learning_model_cifar10.h5')"
      ],
      "metadata": {
        "id": "73JOabVC_ohs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a54df90-7e18-40fc-ab27-5b65fbe1819e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 23s 11ms/step - loss: 1.4565 - accuracy: 0.4854 - val_loss: 1.4473 - val_accuracy: 0.4913\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2888 - accuracy: 0.5438 - val_loss: 1.2469 - val_accuracy: 0.5590\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2374 - accuracy: 0.5652 - val_loss: 1.3071 - val_accuracy: 0.5383\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1985 - accuracy: 0.5762 - val_loss: 1.3255 - val_accuracy: 0.5327\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1724 - accuracy: 0.5875 - val_loss: 1.1912 - val_accuracy: 0.5775\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.1428 - accuracy: 0.5969 - val_loss: 1.2105 - val_accuracy: 0.5680\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1202 - accuracy: 0.6043 - val_loss: 1.2095 - val_accuracy: 0.5712\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.0989 - accuracy: 0.6113 - val_loss: 1.1965 - val_accuracy: 0.5808\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0842 - accuracy: 0.6170 - val_loss: 1.1586 - val_accuracy: 0.5934\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0695 - accuracy: 0.6209 - val_loss: 1.1728 - val_accuracy: 0.5933\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1728 - accuracy: 0.5933\n",
            "Test Accuracy: 0.5932999849319458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Program no : 4\n",
        "# Practicing various strategies of fine tuning.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Define hyperparameters grid for grid search\n",
        "param_grid = {\n",
        "    'classifier__C': [0.1, 1, 10],\n",
        "    'classifier__gamma': [0.1, 0.01, 0.001],\n",
        "    'classifier__kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best parameters found by grid search:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of the best model on the test set:\", accuracy)\n"
      ],
      "metadata": {
        "id": "G1c1fXjCaK-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c341edda-bcea-4af6-b2af-dd66014ba827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found by grid search:\n",
            "{'classifier__C': 0.1, 'classifier__gamma': 0.1, 'classifier__kernel': 'linear'}\n",
            "Accuracy of the best model on the test set: 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Program no : 5\n",
        "#ImplementingGenerative Models:\n",
        "\n",
        "# a) Autoencoder for image reconstruction\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the dataset (MNIST in this case)\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the data to (28, 28, 1) for grayscale images\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train, epochs=10, batch_size=128, shuffle=True, validation_data=(x_test, x_test))\n",
        "\n",
        "# Encode and decode some images from the test set\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Display original and reconstructed images\n",
        "n = 10  # Number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "LN4Ym1by81yC",
        "outputId": "6dbcde7e-adb9-4213-ad47-c5be4c7ce835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 72s 151ms/step - loss: 0.1950 - val_loss: 0.1376\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.1301 - val_loss: 0.1228\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 59s 125ms/step - loss: 0.1201 - val_loss: 0.1157\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 57s 121ms/step - loss: 0.1142 - val_loss: 0.1113\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 58s 123ms/step - loss: 0.1102 - val_loss: 0.1075\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 57s 121ms/step - loss: 0.1073 - val_loss: 0.1048\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 58s 124ms/step - loss: 0.1052 - val_loss: 0.1038\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 57s 121ms/step - loss: 0.1036 - val_loss: 0.1024\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 62s 133ms/step - loss: 0.1023 - val_loss: 0.1008\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 66s 140ms/step - loss: 0.1011 - val_loss: 0.0993\n",
            "313/313 [==============================] - 3s 10ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Program no : 5\n",
        "#ImplementingGenerative Models:\n",
        "# b) Word Prediction using RNN\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sample text data for training\n",
        "text_data = \"The quick brown fox jumps over the lazy dog. The dog barks loudly.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences and labels\n",
        "sequences = tokenizer.texts_to_sequences([text_data])[0]\n",
        "input_sequences = []\n",
        "for i in range(1, len(sequences)):\n",
        "    n_gram_sequence = sequences[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for input to RNN\n",
        "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 50, input_length=max_sequence_length - 1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Function to generate text given a seed word\n",
        "def generate_text(seed_text, next_words, model, max_sequence_length):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        # Sample the word with the highest probability\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Generate text\n",
        "seed_text = \"The quick\"\n",
        "generated_text = generate_text(seed_text, next_words=10, model=model, max_sequence_length=max_sequence_length)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIkZR2NTL8U_",
        "outputId": "4b4064ed-890c-48b8-fa10-d8b621fb6a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.4003 - accuracy: 0.1667\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3937 - accuracy: 0.1667\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3871 - accuracy: 0.1667\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3803 - accuracy: 0.1667\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3731 - accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3655 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.3572 - accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3480 - accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3378 - accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3262 - accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.3130 - accuracy: 0.2500\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2978 - accuracy: 0.2500\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2803 - accuracy: 0.2500\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2601 - accuracy: 0.2500\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2370 - accuracy: 0.2500\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2107 - accuracy: 0.2500\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1816 - accuracy: 0.2500\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.1505 - accuracy: 0.2500\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1184 - accuracy: 0.2500\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0843 - accuracy: 0.2500\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.0432 - accuracy: 0.2500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9923 - accuracy: 0.2500\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.9351 - accuracy: 0.3333\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8779 - accuracy: 0.2500\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8234 - accuracy: 0.2500\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7684 - accuracy: 0.2500\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7090 - accuracy: 0.2500\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6470 - accuracy: 0.2500\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5908 - accuracy: 0.2500\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5505 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.5215 - accuracy: 0.5833\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4860 - accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4476 - accuracy: 0.4167\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4158 - accuracy: 0.3333\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3708 - accuracy: 0.3333\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3139 - accuracy: 0.4167\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2671 - accuracy: 0.4167\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.2081 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1729 - accuracy: 0.5833\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1315 - accuracy: 0.5833\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1049 - accuracy: 0.5833\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0566 - accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0169 - accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9802 - accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.9389 - accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9084 - accuracy: 0.7500\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8809 - accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8485 - accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8122 - accuracy: 0.8333\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7872 - accuracy: 0.8333\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7724 - accuracy: 0.8333\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7688 - accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7641 - accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6905 - accuracy: 0.8333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7354 - accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7290 - accuracy: 0.6667\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6768 - accuracy: 0.8333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7118 - accuracy: 0.6667\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6162 - accuracy: 0.9167\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6582 - accuracy: 0.8333\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5967 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6425 - accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5782 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6060 - accuracy: 0.9167\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5577 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5883 - accuracy: 0.9167\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5411 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5603 - accuracy: 0.9167\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5242 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5447 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5091 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5216 - accuracy: 0.9167\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4940 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5076 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4832 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4696 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4720 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4620 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4557 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4524 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4387 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4411 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4271 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4296 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4211 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4134 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4150 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4035 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3989 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3895 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3836 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3846 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3799 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3694 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3703 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3734 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3603 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3533 - accuracy: 1.0000\n",
            "The quick brown fox jumps over the lazy dog the dog barks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Program no : 5\n",
        "#ImplementingGenerative Models:\n",
        "# c) Image Captioningimport tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 10  # Adjust this number based on your needs\n",
        "\n",
        "# Load pre-trained InceptionV3 model for image feature extraction\n",
        "image_model = InceptionV3(weights='imagenet')\n",
        "image_model = Model(image_model.input, image_model.layers[-2].output)\n",
        "\n",
        "# Function to preprocess and extract features from an image\n",
        "def extract_image_features(image_path):\n",
        "    img = load_img(image_path, target_size=(299, 299))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    features = image_model.predict(img)\n",
        "    features = np.reshape(features, features.shape[1])\n",
        "    return features\n",
        "\n",
        "# Load and preprocess text data for training\n",
        "captions = [\n",
        "    \"A cat sitting on a windowsill\",\n",
        "    \"A group of people playing soccer in a field\",\n",
        "    \"A close-up of a beautiful flower\",\n",
        "    # Add more captions as needed\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(captions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences and labels for training\n",
        "sequences = tokenizer.texts_to_sequences(captions)\n",
        "input_sequences = []\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        n_gram_sequence = sequence[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "# Build the image captioning model\n",
        "image_input = Input(shape=(2048,))\n",
        "image_embedding = Dense(256, activation='relu')(image_input)\n",
        "\n",
        "text_input = Input(shape=(max_sequence_length-1,))\n",
        "text_embedding = Embedding(input_dim=vocab_size, output_dim=50, input_length=max_sequence_length-1)(text_input)\n",
        "text_lstm = LSTM(256)(text_embedding)\n",
        "\n",
        "merged = tf.keras.layers.concatenate([image_embedding, text_lstm])\n",
        "output = Dense(vocab_size, activation='softmax')(merged)\n",
        "\n",
        "captioning_model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "captioning_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the image captioning model (you'll need actual image paths for this)\n",
        "image_paths = [\n",
        "    \"/content/sem1.jpg\",\n",
        "    \"/content/sem2.jpg\",\n",
        "    \"/content/sem3.jpg\",\n",
        "    # Add more image paths as needed\n",
        "]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for image_path in image_paths:\n",
        "        image_features = extract_image_features(image_path)\n",
        "        random_caption = random.choice(captions)\n",
        "        caption_sequence = tokenizer.texts_to_sequences([random_caption])[0]\n",
        "        for i in range(1, len(caption_sequence)):\n",
        "            partial_caption = pad_sequences([caption_sequence[:i]], maxlen=max_sequence_length-1, padding='pre')\n",
        "            X_train = [np.array([image_features]), np.array(partial_caption)]\n",
        "            y_train = to_categorical([caption_sequence[i]], num_classes=vocab_size)\n",
        "            captioning_model.train_on_batch(X_train, y_train)\n",
        "\n",
        "# Function to generate captions for new images\n",
        "def generate_caption(image_path):\n",
        "    image_features = extract_image_features(image_path)\n",
        "    input_text = \"startseq\"\n",
        "    for _ in range(max_sequence_length - 1):\n",
        "        tokenized_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        padded_text = pad_sequences([tokenized_text], maxlen=max_sequence_length-1, padding='pre')\n",
        "        X_gen = [np.array([image_features]), np.array(padded_text)]\n",
        "        predicted_index = np.argmax(captioning_model.predict(X_gen), axis=-1)\n",
        "        predicted_word = next(word for word, index in tokenizer.word_index.items() if index == predicted_index)\n",
        "        if predicted_word == \"endseq\":\n",
        "            break\n",
        "        input_text += \" \" + predicted_word\n",
        "    return input_text\n",
        "\n",
        "# Generate captions for new images\n",
        "new_image_path = \"/content/sem4.jpg\"\n",
        "generated_caption = generate_caption(new_image_path)\n",
        "print(generated_caption)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrogXZmBOc5S",
        "outputId": "be2aa7b6-ed7f-4610-8850-8886b553816c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "1/1 [==============================] - 0s 207ms/step\n",
            "1/1 [==============================] - 0s 211ms/step\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "1/1 [==============================] - 0s 217ms/step\n",
            "1/1 [==============================] - 0s 214ms/step\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "1/1 [==============================] - 0s 368ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "1/1 [==============================] - 0s 211ms/step\n",
            "1/1 [==============================] - 0s 221ms/step\n",
            "1/1 [==============================] - 0s 207ms/step\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 0s 214ms/step\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "1/1 [==============================] - 0s 213ms/step\n",
            "1/1 [==============================] - 0s 212ms/step\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "1/1 [==============================] - 0s 431ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "startseq cat sitting on a windowsill windowsill flower flower\n"
          ]
        }
      ]
    }
  ]
}